Title: My Next Role
Date: 2017-06-20 11:00
Author: Will Wolf
Lang: en
Slug: my-next-role
Status: published
Summary: Beginning the search for an impossibly awesome next role.
Image: images/math_blackboard.jpg

My nine-month open-source ["masters"]({filename}/articles/my-open-source-machine-learning-masters-in-casablanca-morocco.md) in machine learning and statistics — a full-time, self-curated schedule of textbooks, MOOCs, publishing code to my [GitHub](https://github.com/cavaunpeu) and writing to this blog — is soon ending. I'm now starting my search for an impossibly awesome "what's next."

## What I bring
Within your organization, I could immediately bring value to: ETL infrastructure, experimental design and execution, internal and external data products, i.e. algorithm design and deployment, and data evangelism efforts.

## I'm looking for
- A highly technical data science role — equal parts prototyping mathematical models and deploying them to production.
- Excellent, direct technical mentorship, and the opportunity to mentor others.
- A medium-to-large-sized company with a well-established data science team. Alternatively, a smaller company with machine learning at the core of its business that, necessarily, has made significant investments in its data science infrastructure and personnel.
- Large quantities of  unstructured data that do not fit in RAM, ideally.

## Work samples
- [Minimizing the Negative Log-Likelihood, in English]({filename}/articles/minimizing_the_negative_log_likelihood_in_english.md): Statistical underpinnings of the machine learning models we know and love. A walk through random variables, entropy, exponential family distributions, generalized linear models, maximum likelihood estimation, cross entropy, KL-divergence, maximum a posteriori estimation and going "fully Bayesian."
- [Random Effects Neural Networks in Edward and Keras]({filename}/articles/random-effects-neural-networks.md): Coupling nimble probabilistic models with neural architectures in Edward and Keras: "what worked and what didn't," a conceptual overview of random effects, and directions for further exploration.
- [Neurally Embedded Emojis]({filename}/articles/neurally-embedded-emojis.md): Convolutional variational autoencoders for emoji generation and Siamese text-question-emoji-answer models. Keras, bidirectional LSTMs and snarky tweets [@united](https://twitter.com/united) within.
- [Further Exploring Common Probabilistic Models]({filename}/articles/further-exploring-common-probabilistic-models.md): Exploring generative vs. discriminative models, and sampling and variational methods for approximate inference through the lens of Bayes' theorem.
- [Dotify](https://github.com/cavaunpeu/dotify): A well-tested web application that recommends songs via "country arithmetic" and hand-rolled Implicit Matrix Factorization. Built with Flask, React, Webpack, PostgreSQL, Heroku and Docker.

## In three years
Management, I think. I'm a strong communicator, and enjoy teaching things to anyone that will listen.

## Location
NYC/SF, primarily.

## About me
- I once rode a bicycle 7,614.5 kilometers from Istanbul, Turkey to Bishkek, Kyrgyzstan.
- I once taught a university Spanish course, in French, in Guinea-Conakry.
- Mathematics and code keep me smiling from ear to ear.

For more about me, please see my full [bio]({filename}/pages/about.md) and [résumé]({filename}/pages/cv.md). In addition, social links can be found below.
